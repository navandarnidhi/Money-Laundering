{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b247514-bcda-48f9-894e-9117665562c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: azure-storage-blob in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3f2c1cb9-53bc-4d95-bf3c-d1217c1d38ed/lib/python3.10/site-packages (12.22.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3f2c1cb9-53bc-4d95-bf3c-d1217c1d38ed/lib/python3.10/site-packages (from azure-storage-blob) (4.12.2)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.10/site-packages (from azure-storage-blob) (39.0.1)\nRequirement already satisfied: azure-core>=1.28.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3f2c1cb9-53bc-4d95-bf3c-d1217c1d38ed/lib/python3.10/site-packages (from azure-storage-blob) (1.30.2)\nRequirement already satisfied: isodate>=0.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3f2c1cb9-53bc-4d95-bf3c-d1217c1d38ed/lib/python3.10/site-packages (from azure-storage-blob) (0.6.1)\nRequirement already satisfied: requests>=2.21.0 in /databricks/python3/lib/python3.10/site-packages (from azure-core>=1.28.0->azure-storage-blob) (2.28.1)\nRequirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core>=1.28.0->azure-storage-blob) (1.16.0)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.4)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nPredictions have been saved and uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install the required package\n",
    "%pip install azure-storage-blob\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import numpy as np\n",
    "\n",
    "# Define connection string and container name\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=amldatacnak;AccountKey=OD7x5wWUM2IoaFIUIVW1Sq8hI6HzKhnA7Rr4nI+9/OH0jElAD+eksiEoIsIyhjmSlgoynvE5cUwa+AStSBrKkQ==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"amldata\"\n",
    "\n",
    "# Initialize BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Ensure the /dbfs/mnt/ directory exists\n",
    "mnt_dir = \"/dbfs/mnt/\"\n",
    "if not os.path.exists(mnt_dir):\n",
    "    os.makedirs(mnt_dir)\n",
    "\n",
    "# 1. Load the Model from Azure Blob Storage\n",
    "model_blob_path = \"models/random_forest_model.joblib\"\n",
    "model_blob_client = blob_service_client.get_blob_client(container=container_name, blob=model_blob_path)\n",
    "model_file_path = os.path.join(mnt_dir, \"random_forest_model.joblib\")\n",
    "\n",
    "# Download the model\n",
    "with open(model_file_path, \"wb\") as model_file:\n",
    "    model_file.write(model_blob_client.download_blob().readall())\n",
    "\n",
    "# Load the model\n",
    "rf_loaded = joblib.load(model_file_path)\n",
    "\n",
    "# 2. Fetch the User's Data from Azure Blob Storage\n",
    "data_blob_path = \"raw_data/data.csv\"\n",
    "data_blob_client = blob_service_client.get_blob_client(container=container_name, blob=data_blob_path)\n",
    "data_file_path = os.path.join(mnt_dir, \"data.csv\")\n",
    "\n",
    "# Download the user's data\n",
    "with open(data_file_path, \"wb\") as data_file:\n",
    "    data_file.write(data_blob_client.download_blob().readall())\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "new_data = pd.read_csv(data_file_path)\n",
    "\n",
    "# 3. Separate 'From Bank', 'Account', 'To Bank', 'Account.1' into a different DataFrame\n",
    "bank_info_df = new_data[['From Bank', 'Account', 'To Bank', 'Account.1']]\n",
    "\n",
    "# Retain only the relevant features for prediction\n",
    "new_data = new_data[['Amount Received', 'Amount Paid', 'Payment Format', 'Year', 'Month']]\n",
    "\n",
    "# 4. Preprocess the Data\n",
    "categorical_features = ['Payment Format']  # Update with actual categorical features\n",
    "\n",
    "# Load the label encoders from storage\n",
    "label_encoders_path = \"models/label_encoders.joblib\"\n",
    "label_encoders_blob_client = blob_service_client.get_blob_client(container=container_name, blob=label_encoders_path)\n",
    "label_encoders_file_path = os.path.join(mnt_dir, \"label_encoders.joblib\")\n",
    "\n",
    "with open(label_encoders_file_path, \"wb\") as enc_file:\n",
    "    enc_file.write(label_encoders_blob_client.download_blob().readall())\n",
    "\n",
    "label_encoders = joblib.load(label_encoders_file_path)\n",
    "\n",
    "# Handle unseen labels in categorical features\n",
    "for feature in categorical_features:\n",
    "    if feature in new_data.columns:\n",
    "        encoder = label_encoders.get(feature)\n",
    "        if encoder:\n",
    "            new_labels = set(new_data[feature].unique()) - set(encoder.classes_)\n",
    "            if new_labels:\n",
    "                encoder.classes_ = np.concatenate([encoder.classes_, list(new_labels)])\n",
    "            new_data[feature] = encoder.transform(new_data[feature].astype(str))\n",
    "        else:\n",
    "            print(f\"Label encoder for feature '{feature}' not found.\")\n",
    "\n",
    "# 5. Generate Predictions\n",
    "predictions = rf_loaded.predict(new_data)\n",
    "\n",
    "# 6. Decode the 'Payment Format' Column\n",
    "for feature in categorical_features:\n",
    "    if feature in new_data.columns:\n",
    "        encoder = label_encoders.get(feature)\n",
    "        if encoder:\n",
    "            new_data[feature] = encoder.inverse_transform(new_data[feature])\n",
    "\n",
    "# 7. Combine Predictions with the Original DataFrame\n",
    "new_data['predictions'] = predictions\n",
    "final_df = pd.concat([bank_info_df, new_data], axis=1)\n",
    "\n",
    "# 8. Save Results to Azure Blob Storage\n",
    "result_blob_path = \"predictions/predictions_with_results.csv\"\n",
    "result_blob_client = blob_service_client.get_blob_client(container=container_name, blob=result_blob_path)\n",
    "result_file_path = os.path.join(mnt_dir, \"predictions_with_results.csv\")\n",
    "\n",
    "# Save results to CSV\n",
    "final_df.to_csv(result_file_path, index=False)\n",
    "\n",
    "# Upload the results file\n",
    "with open(result_file_path, \"rb\") as result_file:\n",
    "    result_blob_client.upload_blob(result_file, overwrite=True)\n",
    "\n",
    "print(\"Predictions have been saved and uploaded successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "predictions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
